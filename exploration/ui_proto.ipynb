{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import countergen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Choose your dataset\n",
    "Put your file next to the notebook and give it's filename here:\n",
    "\n",
    "[Box where you can put your filename, with a convincing default dataset]\n",
    "\n",
    "[Check that it exists]\n",
    "\n",
    "[Print a few samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = countergen.Dataset.from_jsonl(\"D:\\_Docs\\Programmation\\Python\\Counterfactual-Dataset-Generator\\countergen\\data\\datasets\\doublebind.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choose your converters\n",
    "\n",
    "[Checkboxes with title and explanation]\n",
    "\n",
    "[Link to somewhere if you want to add your own converters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converters = [countergen.SimpleConverter.from_default(\"gender\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert!\n",
    "\n",
    "(Just run this cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_ds = countergen.data_augmentation.generate_all_variations(converters, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Choose models to evaluate\n",
    "\n",
    "[Checkboxs of different models compatible with the dataset you have chosen]\n",
    "\n",
    "[Link to somewhere if you want to evaluate other models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = countergen.get_huggingface_gpt_model_evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b. Choose your metrics\n",
    "\n",
    "[Checkboxs of different metrics & aggregation methods]\n",
    "\n",
    "[Link to somewhere if you want to add your own]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = countergen.aggregators.AveragePerformancePerCategory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate!\n",
    "\n",
    "(Just run this cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = countergen.evaluation.evaluate(aug_ds.samples, model, aggregator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. The results\n",
    "\n",
    "[Beautiful displays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.display([results])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e401bd2233303e7e5c8d55bc5d8195e517ad4c847c84c926c1bcd5146436f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
